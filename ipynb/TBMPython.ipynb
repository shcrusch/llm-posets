{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MsjnDhPzrVaj"
   },
   "source": [
    "TBM定義\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGyFhwzEO8nk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    " \n",
    "def includes(phi,x):\n",
    "  return set(phi).issubset(x)\n",
    "\n",
    "class TBM:\n",
    "  def __init__ (self, n, B, S, X):\n",
    "    \n",
    "    self.set_B(B)\n",
    "    self.set_S(S)\n",
    "    self.n_= n\n",
    "    self.set_Phi(self.S_,self.B_)\n",
    "    self.set_Ssub(self.S_,self.B_)\n",
    "    self.set_Xsub(X)\n",
    "  def fit(self, X, n_iter, stepsize):\n",
    "    \"\"\"Actual implementation of TBM fitting.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples,)\n",
    "            Training vectors, where n_samples is the number of samples and \n",
    "            each element is a tuple of indices of 1s.\n",
    "        n_iter: number of iteration\n",
    "        method: \"grad\"  = gradient descent, \"coor\" coordinate descent\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "    \"\"\"\n",
    "\n",
    "    self.compute_Phat(X)\n",
    "    #print(self.Phat)\n",
    "    self.set_etahat(X)\n",
    "    #print(self.etahat_)\n",
    "    print('gradient_descent')\n",
    "    self.gradient_descent(X,n_iter, stepsize)\n",
    "    \n",
    "    return self\n",
    "  \n",
    "  def set_Xsub(self, X):\n",
    "    self.Xsub = list(dict.fromkeys(X))\n",
    "    self.invXsub = {}\n",
    "    for i in range(len(self.Xsub)):\n",
    "      self.invXsub[self.Xsub[i]] = i\n",
    "  \n",
    "  def set_B(self, B):\n",
    "    \"\"\"\n",
    "    Generate B_ and invB_\n",
    "    Parameters\n",
    "    -----\n",
    "    B : Set of parameters\n",
    "    \n",
    "    invB_ : dict type\n",
    "               indices are vectors of set_B\n",
    "    \"\"\"\n",
    "    self.B_ = B\n",
    "    self.invB_ ={}\n",
    "    for i in range(len(B)):\n",
    "      self.invB_[B[i]] = i\n",
    "      \n",
    "\n",
    "  def set_S(self, S):\n",
    "    \"\"\"\n",
    "    Generate S_ and invS_\n",
    "    Parameters\n",
    "    -----\n",
    "    S : Sample space\n",
    "    \n",
    "    inv_S : dict type\n",
    "               indices are vectors of set_S\n",
    "    \"\"\"\n",
    "    self.S_ = S\n",
    "    self.invS_ ={}\n",
    "    #print(self.S_)\n",
    "    #print(self.invS_)\n",
    "    for i in range(len(S)):\n",
    "      self.invS_[S[i]] = i\n",
    "      \n",
    "  \n",
    "  def set_Phi(self, S, B):\n",
    "    \"\"\"\n",
    "    Phi_[x]= { phi in B | x includes phi }\n",
    "    \"\"\"\n",
    "    self.Phi_ = {}\n",
    "    for x in S:\n",
    "      Phix = []\n",
    "      for phi in B:\n",
    "        if includes(phi,x):\n",
    "          Phix.append(phi)\n",
    "      self.Phi_[x] = Phix\n",
    "\n",
    "  def set_Ssub(self, S, B):\n",
    "    \"\"\"\n",
    "    Ssub [phi]= { x in S | x includes phi } \n",
    "    \"\"\"\n",
    "    self.Ssub_ = {}\n",
    "    for phi in B:\n",
    "      ssub = []\n",
    "      for x in S:\n",
    "        if includes(phi,x):\n",
    "          ssub.append(x)\n",
    "      self.Ssub_[phi] = ssub\n",
    "\n",
    "  def compute_Phat(self, X):\n",
    "    self.Phat = np.zeros(len(self.Xsub))\n",
    "    for xi in X:\n",
    "        self.Phat[self.invXsub[xi]] += 1 / len(X)\n",
    "    \n",
    "  def set_etahat(self, X):\n",
    "    \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples,)\n",
    "            Training vectors, where n_samples is the number of samples and \n",
    "            each element is a tuple of indices of 1s.\n",
    "            \n",
    "    \"\"\"\n",
    "    self.etahat_ = {}\n",
    "    for phi in self.B_:\n",
    "      denom = 0.0\n",
    "      for i in range(len(X)):\n",
    "        denom += 1 if includes(phi, X[i]) else 0\n",
    "      self.etahat_[phi] = denom / len(X)\n",
    "    #print(self.etahat_)\n",
    "          \n",
    "  def init_theta(self):\n",
    "    \n",
    "    self.theta_ = np.zeros(len(self.B_))\n",
    "    self.compute_theta_perp() \n",
    "    #print(self.theta_)\n",
    "  \n",
    "  def compute_theta_perp(self):\n",
    "    \"\"\"\n",
    "    Computing theta_perp\n",
    "    \n",
    "    Returns\n",
    "    -----\n",
    "    theta_\n",
    "    \"\"\"\n",
    "    r = 0.0 \n",
    "    for x in self.S_:\n",
    "      s = 0.0 # sum theta_phi phi(x) for theta in B minus perp\n",
    "      for phi in self.Phi_[x]:\n",
    "        if phi: # is not empty\n",
    "          s += self.get_theta(phi)  \n",
    "      r += np.exp(s)\n",
    "    self.theta_[self.invB_[()]] = -np.log(r)      \n",
    "\n",
    "  def get_theta(self, phi):\n",
    "    \"\"\"\n",
    "    Getting theta\n",
    "    Parameters \n",
    "    -----\n",
    "    phi : element of set_B\n",
    "    \n",
    "    Returns\n",
    "    -----\n",
    "    ret : theta\n",
    "    \"\"\"\n",
    "    return self.theta_[self.invB_[phi]]\n",
    "  \n",
    "  def set_theta(self, phi, value):\n",
    "    \n",
    "    self.theta_[self.invB_[phi]] = value\n",
    "    \n",
    "  \n",
    "  def compute_P(self):\n",
    "    \"\"\"\n",
    "    Computing P\n",
    "    Returns\n",
    "    -----\n",
    "    P_ : len(P_) = len(S_)\n",
    "    \"\"\"\n",
    "    self.P_ = np.zeros(len(self.S_))\n",
    "    for x in self.S_:\n",
    "      self.P_[self.invS_[x]] = np.exp( self.compute_logP(x) )\n",
    "    #print(self.P_)\n",
    "   \n",
    "\n",
    "  def compute_logP(self, xi):\n",
    "    \"\"\"\n",
    "    Computing lopP\n",
    "    Parameters\n",
    "    -----\n",
    "    xi : i th row vector of X\n",
    "    \n",
    "    Returns\n",
    "    -----\n",
    "    ret : logP\n",
    "    \n",
    "    \"\"\"\n",
    "    ret = 0.0;\n",
    "    for phi in self.B_ :\n",
    "      ret +=  self.get_theta(phi) if includes(phi, xi) else 0    \n",
    "    return ret \n",
    "      \n",
    "  def compute_eta(self):\n",
    "    \"\"\"\n",
    "    Computing eta\n",
    "    Returns\n",
    "    -----\n",
    "    eta_ : dict type\n",
    "             len(eta_) = len(B_)\n",
    "    \"\"\"\n",
    "    self.eta_ = {}\n",
    "    for phi in self.B_ :\n",
    "      self.eta_[phi] = 0.0\n",
    "      for x in self.Ssub_[phi] :\n",
    "        self.eta_[phi] += self.P_[self.invS_[x]]\n",
    "        \n",
    "  def compute_ll(self, X):\n",
    "    \"\"\"\n",
    "      Compute log likelihood\n",
    "      Parameters\n",
    "      ----------\n",
    "      X : array-like, shape = [n_samples, n_features]\n",
    "\n",
    "      Returns\n",
    "      ----------\n",
    "      ret :  log-likelihood\n",
    "\n",
    "    \"\"\"\n",
    "    ret = 0.0\n",
    "    #for i in range(len(X)):\n",
    "    #  ret += self.compute_logP(X[i])\n",
    "    for xi in X:\n",
    "      ret += self.compute_logP(xi)\n",
    "    return ret\n",
    "  \n",
    "  def compute_KL(self):\n",
    "    \"\"\"\n",
    "    Computing KL_divergence\n",
    "    \n",
    "    Parameter\n",
    "    -----\n",
    "    X : array-like, shape (n_samples,)\n",
    "            Training vectors, where n_samples is the number of samples and \n",
    "            each element is a tuple of indices of 1s. \n",
    "    -----\n",
    "    \"\"\"\n",
    "    ret = 0.0\n",
    "    for xi in self.Xsub:\n",
    "      ret += self.Phat[self.invXsub[xi]] * (np.log(self.Phat[self.invXsub[xi]]) - self.compute_logP(xi))\n",
    "    \n",
    "    return ret\n",
    "  \n",
    "  def compute_squared_gradient(self):\n",
    "      ret = 0.0\n",
    "      for phi in self.B_:\n",
    "#      if phi: # is not empty \n",
    "        ret += (self.etahat_[phi] - self.eta_[phi] ) ** 2\n",
    "      \n",
    "      return ret\n",
    "\n",
    "\n",
    "  def gradient_descent(self, X, max_epoch, step):  \n",
    "    \"\"\"\n",
    "    Actual implementation gradient_descent\n",
    "    Parameters \n",
    "    -----\n",
    "    X : array-like, shape (n_samples,)\n",
    "            Training vectors, where n_samples is the number of samples and \n",
    "            each element is a tuple of indices of 1s. \n",
    "    max_epoch\n",
    "    step \n",
    "    \"\"\"\n",
    "    self.init_theta()\n",
    "    start = time.time()\n",
    "    for epoch in range(max_epoch):\n",
    "      self.compute_P()\n",
    "      self.compute_eta()\n",
    "      #print(self.compute_ll(X))\n",
    "      print(epoch ,\":\",  \"KL divergence:\",f'{self.compute_KL():.8f}' ,\" time : %4.2f\"% (time.time()-start),\"Squared Gradient:\",self.compute_squared_gradient())\n",
    "      for phi in self.B_:\n",
    "        if phi: # is not empty\n",
    "          new_theta_phi = self.get_theta(phi) + step * (self.etahat_[phi] - self.eta_[phi] )\n",
    "          self.set_theta(phi, new_theta_phi)\n",
    "      self.compute_theta_perp()\n",
    "\n",
    "\n",
    "  def coordinate_descent(self, X, max_epoch, step_init=2):\n",
    "    \"\"\"\n",
    "    Actual implementation coodinate_descent\n",
    "    Parameters \n",
    "    -----\n",
    "    X : array-like, shape (n_samples,)\n",
    "            Training vectors, where n_samples is the number of samples and \n",
    "            each element is a tuple of indices of 1s.\n",
    "    max_epoch\n",
    "    -----\n",
    "    \n",
    "    \"\"\"\n",
    "    u = {}\n",
    "    for x in self.S_:\n",
    "      u[x] = 1.0\n",
    "    Z = len(self.S_)\n",
    "    self.theta_ = np.zeros(len(self.B_)) \n",
    "    start = time.time()\n",
    "    \n",
    "    for epoch in range(max_epoch):\n",
    "      self.set_theta((), -np.log(Z) )\n",
    "      self.compute_P()\n",
    "      self.compute_eta()\n",
    "      sg=self.compute_squared_gradient()\n",
    "      kl=self.compute_KL()\n",
    "      #print(self.compute_ll(X))\n",
    "      print(epoch ,\":\",  \"KL divergence:\",f'{kl:.8f}' ,\" time : %4.2f\"% (time.time()-start),\"Squared Gradient:\",f'{sg:10f}')\n",
    "      index = np.random.RandomState(seed=2019).permutation(range(len(self.B_)-1)) #exclude the bottom\n",
    "     \n",
    "      #compute etahat\n",
    "      for iter in range(len(self.B_) -1):\n",
    "        phi = self.B_[index[iter] +1 ]\n",
    "        Ssub=self.Ssub_[phi]\n",
    "        etahat_phi = self.etahat_[phi] \n",
    "        eta_phi = 0.0\n",
    "        for x in Ssub:\n",
    "            eta_phi += u[x]\n",
    "        eta_phi /= Z\n",
    "\n",
    "        sigma = eta_phi * Z\n",
    "        tau = (1-eta_phi) * Z\n",
    "        delta = np.log(tau/sigma * etahat_phi/(1-etahat_phi))\n",
    "\n",
    "\n",
    "        step_base = step_init \n",
    "        new_eta_phi = eta_phi\n",
    "        \n",
    "        while np.abs(etahat_phi - new_eta_phi) > 0.0001:      \n",
    "          step = step_base * ( self.etahat_[phi] - new_eta_phi )\n",
    "          #print(etahat_phi - new_eta_phi, step)\n",
    "          #\n",
    "          step = delta\n",
    "          \n",
    "          u_new, Z_new = self.update_uZ(u, Z, step, phi)\n",
    "          \n",
    "          eta_phi_step  = 0.0\n",
    "          for x in Ssub:\n",
    "              eta_phi_step += u_new[x]\n",
    "          eta_phi_step /= Z_new\n",
    "\n",
    "          if np.abs(etahat_phi - new_eta_phi) >  np.abs(etahat_phi - eta_phi_step ): #if it gets better\n",
    "            self.set_theta(phi, self.get_theta(phi) + step )\n",
    "            new_eta_phi = eta_phi_step\n",
    "            u, Z = u_new, Z_new            \n",
    "          else: \n",
    "            step_base *= 0.3\n",
    "     \n",
    "      \n",
    "  def update_uZ(self, u, Z, step, phi):\n",
    "    \"\"\"\n",
    "    Updating u,Z\n",
    "    Parameters\n",
    "    -----\n",
    "    u\n",
    "    Z\n",
    "    step\n",
    "    phi\n",
    "    \n",
    "    \"\"\"\n",
    "    u_new = u.copy()\n",
    "    Ssub=self.Ssub_[phi]\n",
    "    for x in Ssub:\n",
    "        u_new[x] *= np.exp(step)\n",
    "    Z_new = Z\n",
    "    for x in Ssub:\n",
    "        Z_new += u[x] * (np.exp(step) -1)\n",
    "    return u_new, Z_new\n",
    "  \n",
    "  def coordinate_descent2(self, X, max_epoch):  \n",
    "    \"\"\"\n",
    "    Actual implementation gradient_descent\n",
    "    Parameters \n",
    "    -----\n",
    "    X : array-like, shape (n_samples,)\n",
    "            Training vectors, where n_samples is the number of samples and \n",
    "            each element is a tuple of indices of 1s. \n",
    "    max_epoch\n",
    "    \"\"\"\n",
    "    self.init_theta()\n",
    "    start = time.time()\n",
    "    self.compute_P()\n",
    "    self.compute_eta()\n",
    "    for epoch in range(max_epoch):\n",
    "      \n",
    "      print(epoch ,\":\",  \"KL divergence:\",f'{self.compute_KL():.8f}' ,\" time : %4.2f\"% (time.time()-start),\"Squared Gradient:\",self.compute_squared_gradient())\n",
    "      index = np.random.RandomState(seed=2019).permutation(range(len(self.B_)-1)) #exclude the bottom\n",
    "      #index = range(len(self.B_)-1)\n",
    "      for iter in range(len(self.B_) -1):\n",
    "        \n",
    "        phi = self.B_[index[iter] +1 ]\n",
    "        #print(phi)\n",
    "        s, t = self.compute_st(phi)\n",
    "        d = np.log(t / s * self.etahat_[phi] / (1 - self.etahat_[phi]) )\n",
    "        #print(d)\n",
    "        new_theta_phi = self.get_theta(phi) + d\n",
    "        self.set_theta(phi, new_theta_phi)\n",
    "        self.theta_[self.invB_[()]] = -np.log(s * np.exp(d) + t)\n",
    "        self.compute_P()\n",
    "        self.compute_eta()\n",
    "  \n",
    "  def compute_st(self,phi):\n",
    "    s = self.eta_[phi] * np.exp(-self.theta_[self.invB_[()]])\n",
    "    t = (1 - self.eta_[phi]) * np.exp(-self.theta_[self.invB_[()]])\n",
    "    \n",
    "    return s,t\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YqDh7RfLrKPq"
   },
   "source": [
    "データ取得\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "8AfMivPoicmc",
    "outputId": "ad8b058d-22d5-4259-89fa-ec93d41f40eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-09-22 05:17:05--  http://fimi.uantwerpen.be/data/chess.dat\n",
      "Resolving fimi.uantwerpen.be (fimi.uantwerpen.be)... 143.129.69.1\n",
      "Connecting to fimi.uantwerpen.be (fimi.uantwerpen.be)|143.129.69.1|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 342294 (334K)\n",
      "Saving to: ‘chess.dat’\n",
      "\n",
      "\r",
      "chess.dat             0%[                    ]       0  --.-KB/s               \r",
      "chess.dat           100%[===================>] 334.27K  --.-KB/s    in 0.07s   \n",
      "\n",
      "2019-09-22 05:17:05 (4.97 MB/s) - ‘chess.dat’ saved [342294/342294]\n",
      "\n",
      "chess.dat  sample_data\n"
     ]
    }
   ],
   "source": [
    "!wget http://fimi.uantwerpen.be/data/chess.dat\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "9z0WxsEwDej1",
    "outputId": "ec8bfd57-f3f9-4985-b1bf-69c73afe1a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-09-01 13:16:30--  http://fimi.uantwerpen.be/data/retail.dat\n",
      "Resolving fimi.uantwerpen.be (fimi.uantwerpen.be)... 143.129.69.1\n",
      "Connecting to fimi.uantwerpen.be (fimi.uantwerpen.be)|143.129.69.1|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4167490 (4.0M)\n",
      "Saving to: ‘retail.dat’\n",
      "\n",
      "retail.dat          100%[===================>]   3.97M  4.66MB/s    in 0.9s    \n",
      "\n",
      "2019-09-01 13:16:32 (4.66 MB/s) - ‘retail.dat’ saved [4167490/4167490]\n",
      "\n",
      "retail.dat  sample_data\n"
     ]
    }
   ],
   "source": [
    "!wget http://fimi.uantwerpen.be/data/retail.dat\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "uxiN1Jh1EGo9",
    "outputId": "b08303c0-4f42-4dab-a9ce-344197b44b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73)\n"
     ]
    }
   ],
   "source": [
    "X= []\n",
    "m = 1000\n",
    "n = -1\n",
    "with open(\"chess.dat\") as f:\n",
    "  for line in f:\n",
    "    xi =line.split()\n",
    "    xi_int = [ int(xij)  for xij in xi ]\n",
    "        \n",
    "    if m > min(xi_int):\n",
    "      m = min(xi_int)\n",
    "\n",
    "    if n < max(xi_int):\n",
    "          \n",
    "      n = max(xi_int)\n",
    "with open(\"chess.dat\") as f:\n",
    "  for line in f:\n",
    "    xi = line.split()\n",
    "    xi_int = [ int(xij) - m for xij in xi ]\n",
    "    X.append(tuple(xi_int))\n",
    "n = n-m+1\n",
    "print(m)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ykvQ-LRNrlZI"
   },
   "source": [
    "その他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "ujjAsRf4iZ7F",
    "outputId": "6c3ed6f3-f571-4462-ec6e-cb4812ee4232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent\n",
      "0 : KL divergence: 0.51082562  time : 0.00 Squared Gradient: 0.09333333333333328\n",
      "1 : KL divergence: 0.46792210  time : 0.00 Squared Gradient: 0.06551792740676113\n",
      "2 : KL divergence: 0.43788786  time : 0.00 Squared Gradient: 0.045547647532480105\n",
      "3 : KL divergence: 0.41700812  time : 0.00 Squared Gradient: 0.03174533694167355\n",
      "4 : KL divergence: 0.40241605  time : 0.01 Squared Gradient: 0.022446057233144846\n",
      "5 : KL divergence: 0.39204449  time : 0.01 Squared Gradient: 0.016272982821671396\n",
      "6 : KL divergence: 0.38446983  time : 0.01 Squared Gradient: 0.012199836444544544\n",
      "7 : KL divergence: 0.37874062  time : 0.01 Squared Gradient: 0.00950869833520501\n",
      "8 : KL divergence: 0.37423247  time : 0.01 Squared Gradient: 0.007716821501045386\n",
      "9 : KL divergence: 0.37053960  time : 0.01 Squared Gradient: 0.006507378858732223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TBM at 0x7fa618133da0>"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X =[ (0,1,2), (2,4), (4,)]\n",
    "\n",
    "B = [(),(2,),(4,),(2,4)]\n",
    "S = list(dict.fromkeys(B+X))\n",
    "tbm = TBM(5, B, S, X)\n",
    "tbm.fit(X,10,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "s-MwCQqzJ0pE",
    "outputId": "d362d2b8-7d07-485c-b6bc-b1bbdb70cabf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : KL divergence: 0.74187468  time : 0.00 Squared Gradient:   0.260000\n",
      "1 : KL divergence: 0.19906580  time : 0.00 Squared Gradient:   0.005547\n",
      "2 : KL divergence: 0.17489901  time : 0.01 Squared Gradient:   0.001375\n",
      "3 : KL divergence: 0.16542358  time : 0.01 Squared Gradient:   0.001017\n",
      "4 : KL divergence: 0.15822019  time : 0.01 Squared Gradient:   0.000766\n",
      "5 : KL divergence: 0.15272948  time : 0.01 Squared Gradient:   0.000595\n",
      "6 : KL divergence: 0.14841842  time : 0.01 Squared Gradient:   0.000474\n",
      "7 : KL divergence: 0.14495751  time : 0.01 Squared Gradient:   0.000385\n",
      "8 : KL divergence: 0.14212547  time : 0.02 Squared Gradient:   0.000318\n",
      "9 : KL divergence: 0.13976994  time : 0.02 Squared Gradient:   0.000267\n"
     ]
    }
   ],
   "source": [
    "X =[ (0,1,2), (2,4), (4,) , (4,),  (4,), (4,) ]\n",
    "B = [(),(2,),(4,),(2,4)]\n",
    "S = list(dict.fromkeys(B+X))\n",
    "tbm = TBM(5, B, S, X)\n",
    "tbm.compute_Phat(X)\n",
    "tbm.set_etahat(X)\n",
    "tbm.coordinate_descent(X,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "w_fbN2zNZa3S",
    "outputId": "8280ab56-a5eb-4f2b-c81d-6a35c02e23bc"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-882add8016c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mphi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mphi_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0metahat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincludes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0metahat\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "n = D.max().max() + 1 # including 0\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "phi_all = list(itertools.combinations(range(n),1)) + list(itertools.combinations(range(n),2))\n",
    "\n",
    "B = []\n",
    "for phi in phi_all:\n",
    "  etahat = 0.0\n",
    "  for x in Y:\n",
    "    if includes(phi, x):\n",
    "      etahat += 1\n",
    "#  etahat /= len(X)\n",
    "  #print(etahat)\n",
    "  if etahat > 0:\n",
    "    B.append(phi)\n",
    "print(len(B))\n",
    "print(len(phi_all))\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmF_QXH7-kyv"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2A0LeZ8Zrvzh"
   },
   "source": [
    "Bをファイルから取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "-2pUOsZ2BV-5",
    "outputId": "37c63340-2447-4bfb-c519-97788fe15bca"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5c2e8a8d365b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lzcMcF4P86Id"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_B_from(filename):\n",
    "  # file format:\n",
    "  # each line is a frequent itemset with 1-start\n",
    "  # ignore the first line that represents \"bottom\"\n",
    "  # e.g.\n",
    "  #   \n",
    "  # 1 \n",
    "  # 2\n",
    "  # 3\n",
    "  # 1 2\n",
    "  # 1 3\n",
    "  # 1 2 3\n",
    "  Bfile = pd.read_csv(filename, header=None, sep=' ',names=[0,1])\n",
    "  Bfile.head()\n",
    "  B1=[(),]\n",
    "  B2=[]\n",
    "  for i in range(len(Bfile)):\n",
    "    if pd.isnull(Bfile.at[i,1]): #要素が一つのものだけをB1に入れる\n",
    "      B1.append((Bfile.loc[i,0]-1,)) #全ての要素-1\n",
    "\n",
    "  for j in range(len(Bfile)):\n",
    "    if pd.isnull(Bfile.at[j,1])==0: #要素が二つのものをB2に入れる\n",
    "      B2.append((Bfile.loc[j,0]-1,int(Bfile.loc[j,1]-1))) #全ての要素-1\n",
    "  B1.sort()\n",
    "  B2.sort()\n",
    "  B=B1+B2\n",
    "\n",
    "  return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4YMZlv7fNOyf"
   },
   "outputs": [],
   "source": [
    "B = get_B_from(\"chess.dat_itemsets\")\n",
    "S = list(dict.fromkeys(B+X))\n",
    "tbm = TBM(n,B,S,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "9O1mdMnE-Lcf",
    "outputId": "62e381d6-17ef-4cfb-a07b-36933fc8cb6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent\n",
      "0 : KL divergence: 0.11038542  time : 4.81 Squared Gradient: 2.029937764555959\n",
      "1 : KL divergence: 0.09208482  time : 10.02 Squared Gradient: 1.323405437670419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TBM at 0x7fa6186564e0>"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbm.fit(X,2,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "hb4rQ2xaA01w",
    "outputId": "95cd042e-cf41-406c-f33a-edea97cbf60b"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cb7f86d829f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_Phat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoordinate_descent2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-31ef1ceb5b21>\u001b[0m in \u001b[0;36mcoordinate_descent2\u001b[0;34m(self, X, max_epoch)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"KL divergence:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{self.compute_KL():.8f}'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\" time : %4.2f\"\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Squared Gradient:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_squared_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m       \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#exclude the bottom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       \u001b[0;31m#index = range(len(self.B_)-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-31ef1ceb5b21>\u001b[0m in \u001b[0;36mcompute_squared_gradient\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mphi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;31m#      if phi: # is not empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0metahat_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TBM' object has no attribute 'etahat_'"
     ]
    }
   ],
   "source": [
    "tbm.compute_Phat(X)\n",
    "\n",
    "tbm.coordinate_descent2(X,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "u5FNpZySmNVi",
    "outputId": "af64cbb6-579f-4102-a7b6-593de558cfb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : KL divergence: 0.11038542  time : 4.33 Squared Gradient:   2.029938\n",
      "1 : KL divergence: 0.00644338  time : 12.24 Squared Gradient:   0.000673\n",
      "2 : KL divergence: 0.00427300  time : 19.94 Squared Gradient:   0.000132\n",
      "3 : KL divergence: 0.00370289  time : 27.40 Squared Gradient:   0.000065\n",
      "4 : KL divergence: 0.00334168  time : 34.68 Squared Gradient:   0.000045\n",
      "5 : KL divergence: 0.00308407  time : 41.78 Squared Gradient:   0.000034\n",
      "6 : KL divergence: 0.00288866  time : 48.72 Squared Gradient:   0.000030\n",
      "7 : KL divergence: 0.00272666  time : 55.66 Squared Gradient:   0.000025\n",
      "8 : KL divergence: 0.00259071  time : 62.60 Squared Gradient:   0.000022\n",
      "9 : KL divergence: 0.00247486  time : 69.42 Squared Gradient:   0.000020\n"
     ]
    }
   ],
   "source": [
    "tbm.compute_Phat(X)\n",
    "tbm.set_etahat(X)\n",
    "tbm.coordinate_descent(X,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "colab_type": "code",
    "id": "gR5rKsqnl5Hw",
    "outputId": "eec05d34-51f3-41d5-c42c-1cf9689e6014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-463682b5c23b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "A = [(1,2,3),(4,5,6),(7,8,9)]\n",
    "print(A[0][1])\n",
    "for i in range(len(A)):\n",
    "  for j in range(len(A[i])):\n",
    "    A[i][j] = A[i][j] -1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QU3huzuUz0WR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chess.dat\t      kosarak.dat\t     retail.dat\r\n",
      "chess.dat_itemsets    kosarak.dat_itemsets   retail.dat_itemsets\r\n",
      "connect.dat\t      mushroom.dat\r\n",
      "connect.dat_itemsets  mushroom.dat_itemsets\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TBMPython.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
